# Architecture Diagram

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    YOUR M3 MAX MACBOOK PRO                   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Terminal (Your Interface)                 â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚     enhanced_code_agent.py                      â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Rich Terminal UI                        â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Syntax highlighting                   â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Markdown rendering                    â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Pretty tables & trees                 â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Streaming display                     â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                      â†•                           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Agent Core                              â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Conversation manager                  â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Context builder                       â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Tool orchestrator                     â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Response processor                    â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                      â†•                           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Tool System                             â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ read_file                        â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ write_file                       â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ edit_file                        â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ run_command                      â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ list_files                       â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ search_files                     â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ create_directory                 â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ â€¢ [your custom tools...]           â”‚ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                      â†•                           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Ollama Client                           â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ HTTP requests                         â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Streaming handler                     â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Token processing                      â”‚   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚                            â†•                                â”‚
â”‚                   (localhost:11434)                         â”‚
â”‚                            â†•                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Ollama Server                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  Model Runtime                                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ qwen2.5-coder:7b (or your choice)          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Token generation                            â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Context management                          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Memory optimization                         â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚                            â†•                                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Your File System                        â”‚  â”‚
â”‚  â”‚  â€¢ Source code                                       â”‚  â”‚
â”‚  â”‚  â€¢ Configuration files                               â”‚  â”‚
â”‚  â”‚  â€¢ Project files                                     â”‚  â”‚
â”‚  â”‚  â€¢ All your data (stays local!)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

### 1. User Query Flow
```
User Input
    â†“
Terminal UI (Rich)
    â†“
Agent Core (conversation history + context)
    â†“
Prompt Builder (system prompt + user query)
    â†“
Ollama Client (HTTP POST with streaming)
    â†“
Ollama Server (model inference)
    â†“
Streaming Tokens Back
    â†“
Live Display in Terminal
    â†“
Tool Extraction & Execution
    â†“
Final Response to User
```

### 2. Tool Execution Flow
```
Agent identifies tool call in response
    â†“
Parse tool name and arguments
    â†“
Validate tool exists
    â†“
Execute tool function
    â†“
Capture tool output
    â†“
Display result in terminal
    â†“
Add result to conversation context
    â†“
Continue conversation
```

## Component Responsibilities

### 1. **Rich Terminal UI**
- Renders beautiful terminal output
- Syntax highlighting for code
- Markdown formatting
- Progress indicators
- Live streaming display

### 2. **Agent Core**
- Manages conversation history
- Builds prompts with context
- Coordinates tool execution
- Handles errors gracefully
- Maintains working directory state

### 3. **Tool System**
- Defines available tools
- Executes tool functions
- Validates tool inputs
- Returns structured results
- Extensible architecture

### 4. **Ollama Client**
- Communicates with Ollama API
- Handles streaming responses
- Manages timeouts
- Processes tokens
- Error handling

### 5. **Ollama Server**
- Runs the LLM model
- Generates tokens
- Manages GPU/CPU usage
- Handles concurrent requests
- Optimizes memory

## Communication Patterns

### Agent â†” Ollama
```
POST http://localhost:11434/api/generate
{
  "model": "qwen2.5-coder:7b",
  "prompt": "<system prompt>\n\n<conversation history>\n\nuser: ...",
  "stream": true,
  "options": {
    "temperature": 0.7,
    "num_predict": 2048
  }
}

Response (streaming):
{"response": "I", "done": false}
{"response": "'ll", "done": false}
{"response": " help", "done": false}
...
{"response": "", "done": true}
```

### Tool Call Pattern
```
Agent Response: "Let me read that file for you.

TOOL[read_file](main.py)

Now I'll analyze the code..."

â†“ Agent extracts tool call
â†“ Executes: agent.tools['read_file'].execute('main.py')
â†“ Tool reads file and displays with syntax highlighting
â†“ Returns: "Successfully read 150 characters from main.py"
â†“ Agent continues with analysis
```

## Privacy & Security

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Your Machine (M3 Max)          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  All processing happens here  â”‚ â”‚
â”‚  â”‚                                â”‚ â”‚
â”‚  â”‚  â€¢ Code never leaves machine  â”‚ â”‚
â”‚  â”‚  â€¢ No external API calls      â”‚ â”‚
â”‚  â”‚  â€¢ No data collection         â”‚ â”‚
â”‚  â”‚  â€¢ No internet required       â”‚ â”‚
â”‚  â”‚                                â”‚ â”‚
â”‚  â”‚  Your Data + Local Model =    â”‚ â”‚
â”‚  â”‚  Complete Privacy ğŸ”’           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         âŒ No cloud connections
         âŒ No API keys needed
         âŒ No tracking
```

## Extensibility Points

### 1. Add New Tools
```python
# In EnhancedCodeAgent class
def _register_tools(self):
    tools['your_tool'] = Tool(
        'your_tool',
        'Description',
        self._your_tool_func
    )
```

### 2. Customize System Prompt
```python
def _build_system_prompt(self):
    return """Your custom instructions here..."""
```

### 3. Add New Commands
```python
# In main() function
elif cmd == '/your_command':
    your_command_logic()
```

### 4. Integrate External Services
```python
# Add to tool system
def _call_api(self, endpoint):
    response = requests.get(endpoint)
    return response.json()
```

## Deployment Options

### Local Development
```
Terminal â†’ Agent â†’ Ollama (localhost) â†’ Local Files
```

### Network Setup (Advanced)
```
Terminal 1 (laptop) â†’ Agent
                       â†“
           Network â†’ Ollama Server (desktop)
                       â†“
                   Powerful GPU Model
```

### Container Setup (Future)
```
Docker Container
â”œâ”€â”€ Agent
â”œâ”€â”€ Ollama
â””â”€â”€ Isolated File System
```

## Performance Characteristics

### With M3 Max (36GB RAM)

**Small Models (3B)**
- Speed: 60+ tokens/sec
- Memory: ~2GB
- Latency: Instant response
- Use case: Quick queries

**Medium Models (7B)** â­ Recommended
- Speed: 30-50 tokens/sec
- Memory: ~5GB
- Latency: Fast response
- Use case: General coding

**Large Models (13-16B)**
- Speed: 15-25 tokens/sec
- Memory: ~9-10GB
- Latency: Good response
- Use case: Complex tasks

**Very Large Models (30B+)**
- Speed: 5-10 tokens/sec
- Memory: ~20GB
- Latency: Slower but acceptable
- Use case: Critical tasks

## State Management

```
Session State:
â”œâ”€â”€ conversation_history []
â”œâ”€â”€ working_directory Path
â”œâ”€â”€ model str
â”œâ”€â”€ tools Dict[str, Tool]
â””â”€â”€ session_start datetime

Conversation History:
[
  {"role": "user", "content": "..."},
  {"role": "assistant", "content": "..."},
  ...
]

Tool State:
{
  "tool_name": Tool(name, description, func),
  ...
}
```

## Error Handling

```
User Input
    â†“
Try: Parse & Validate
    â†“
Try: Call Ollama
    â†“  (timeout, connection error, etc.)
    â†“
Catch: Show user-friendly error
    â†“
Try: Execute Tools
    â†“  (file not found, permission error, etc.)
    â†“
Catch: Return error message
    â†“
Continue conversation
```

---

**This architecture ensures:**
- âœ… Complete privacy (everything local)
- âœ… Fast responses (optimized for M3 Max)
- âœ… Extensibility (easy to add features)
- âœ… Reliability (proper error handling)
- âœ… User control (you own the system)
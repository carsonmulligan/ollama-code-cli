# Local Code Agent - Cheat Sheet ğŸ“‹

Quick reference for using your local code agent.

---

## ğŸš€ Installation (One-Time)

```bash
# 1. Install Ollama
brew install ollama

# 2. Pull a model
ollama pull qwen2.5-coder:7b

# 3. Run setup
./setup.sh
```

---

## âš¡ Quick Start

```bash
# Terminal 1: Start Ollama
ollama serve

# Terminal 2: Start Agent
python3 enhanced_code_agent.py
```

---

## ğŸ’¬ Agent Commands

| Command | Description | Example |
|---------|-------------|---------|
| `/help` | Show help | `/help` |
| `/clear` | Clear history | `/clear` |
| `/model` | Switch model | `/model llama3.2:3b` |
| `/pwd` | Show directory | `/pwd` |
| `/cd` | Change directory | `/cd ~/projects` |
| `/tools` | List tools | `/tools` |
| `/exit` | Quit agent | `/exit` |

---

## ğŸ› ï¸ Available Tools

| Tool | Purpose | Usage |
|------|---------|-------|
| `read_file` | View file contents | "Read main.py" |
| `write_file` | Create new file | "Create test.py with hello world" |
| `edit_file` | Modify file | "Add error handling to parse()" |
| `run_command` | Execute shell command | "Run pytest" |
| `list_files` | Browse directory | "List all Python files" |
| `search_files` | Find files | "Search for config.yaml" |
| `create_directory` | Make folder | "Create tests directory" |

---

## ğŸ’¡ Example Queries

### File Operations
```
Read the contents of main.py
Create a new file called utils.py with helper functions
Edit config.json to change the port to 8080
List all files in the src directory
Search for TODO comments in the project
```

### Code Tasks
```
Write a Python function to parse CSV files
Add error handling to the authentication module
Refactor the database connection code
Create unit tests for the API endpoints
Optimize this SQL query for better performance
```

### Project Management
```
Show me the project structure
Find all files larger than 1MB
List all Python files modified in the last week
Create a new React component for user profiles
Set up a basic Express.js server
```

### Debugging
```
Help me debug this error: [paste error]
Explain what this code does
Why is this function failing?
Run the tests and show me any failures
Check for syntax errors in app.js
```

---

## ğŸ¨ Response Formatting

Agent automatically formats:
- **Code blocks** with syntax highlighting
- **File contents** with line numbers
- **Command output** with clear formatting
- **Errors** in red
- **Success** in green

---

## âš™ï¸ Model Selection

### For Speed ğŸš€
```bash
ollama pull llama3.2:3b
/model llama3.2:3b
```

### For Coding â­ (Recommended)
```bash
ollama pull qwen2.5-coder:7b
/model qwen2.5-coder:7b
```

### For Quality ğŸ¯
```bash
ollama pull deepseek-coder-v2:16b
/model deepseek-coder-v2:16b
```

---

## ğŸ› Common Issues & Fixes

### Can't Connect to Ollama
```bash
# Check if running
curl http://localhost:11434/api/tags

# Start it
ollama serve
```

### Model Not Found
```bash
# List available models
ollama list

# Pull a model
ollama pull llama3.2:3b
```

### Slow Responses
```bash
# Use smaller model
/model llama3.2:3b

# Or check system resources
top
```

### Permission Errors
```bash
# Make scripts executable
chmod +x *.py *.sh

# Run with python directly
python3 enhanced_code_agent.py
```

---

## ğŸ”§ Configuration Tips

### Change Temperature (Randomness)
Edit in `enhanced_code_agent.py`:
```python
"temperature": 0.7  # Lower = more focused
                    # Higher = more creative
```

### Adjust Context Window
```python
"num_ctx": 4096  # Smaller = faster
                 # Larger = more context
```

### Limit History
```python
for msg in self.conversation_history[-6:]:  # Keep last 6
```

---

## ğŸ“Š Performance Guide

### M3 Max (36GB RAM)

| Model Size | Speed | Memory | Best For |
|------------|-------|--------|----------|
| 3B | âš¡âš¡âš¡âš¡âš¡ | 2GB | Quick tasks |
| 7B | âš¡âš¡âš¡âš¡ | 5GB | General coding â­ |
| 13B | âš¡âš¡âš¡ | 8GB | Complex tasks |
| 16B | âš¡âš¡âš¡ | 10GB | Best quality |
| 30B+ | âš¡âš¡ | 20GB+ | Critical work |

---

## ğŸ¯ Workflow Examples

### Starting a New Project
```
â¯ Create a new Python project structure
â¯ Add a README with project description
â¯ Create a requirements.txt with common packages
â¯ Set up a basic test framework
```

### Code Review
```
â¯ Read main.py
â¯ Analyze this code for potential issues
â¯ Suggest improvements for better performance
â¯ Add docstrings to all functions
```

### Debugging Session
```
â¯ Read the error logs
â¯ Explain what this error means
â¯ Show me the function that's failing
â¯ Fix the bug and update the file
â¯ Run the tests to verify
```

---

## ğŸ” Privacy Features

âœ… **Everything Local**
- No internet required
- No API calls
- No data collection
- Your code never leaves your machine

âœ… **Full Control**
- Modify any part
- Add custom tools
- Change behavior
- Own your data

---

## ğŸ“š File Structure

```
your-agent/
â”œâ”€â”€ enhanced_code_agent.py  # Main app â­
â”œâ”€â”€ local_code_agent.py     # Simple version
â”œâ”€â”€ config.example.py       # Configuration
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ setup.sh                # Setup script
â”œâ”€â”€ README.md               # Full docs
â”œâ”€â”€ QUICKSTART.md           # Fast setup
â”œâ”€â”€ ARCHITECTURE.md         # System design
â””â”€â”€ CHEATSHEET.md          # This file
```

---

## ğŸš¦ Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `Ctrl+C` | Interrupt (don't quit) |
| `Ctrl+D` | Exit |
| `â†‘` / `â†“` | Command history |
| `Tab` | Autocomplete paths |

---

## ğŸ Pro Tips

1. **Start with simple models** - Try 3B first, upgrade if needed
2. **Use descriptive queries** - More context = better results
3. **Chain tasks** - Let the agent do multiple steps
4. **Clear history** - Use `/clear` for fresh context
5. **Check /tools** - See what's available
6. **Read the docs** - ARCHITECTURE.md has deep details
7. **Customize freely** - It's your agent!

---

## ğŸ”„ Ollama Commands

```bash
# List models
ollama list

# Pull model
ollama pull <model>

# Remove model
ollama rm <model>

# Show model info
ollama show <model>

# Run model directly
ollama run <model>

# Stop server
pkill ollama

# Check version
ollama --version
```

---

## ğŸ“¦ Recommended Models

### Top 3 for Coding

1. **qwen2.5-coder:7b** â­ Best balance
   ```bash
   ollama pull qwen2.5-coder:7b
   ```

2. **deepseek-coder-v2:16b** ğŸ¯ Best quality
   ```bash
   ollama pull deepseek-coder-v2:16b
   ```

3. **llama3.2:3b** ğŸš€ Fastest
   ```bash
   ollama pull llama3.2:3b
   ```

---

## ğŸ†˜ Getting Help

1. **In the agent**: `/help`
2. **Documentation**: `README.md`
3. **Architecture**: `ARCHITECTURE.md`
4. **Ollama docs**: https://github.com/ollama/ollama

---

## âœ¨ Next Steps

1. âœ… Install and run agent
2. âœ… Try basic commands
3. âœ… Create a simple file
4. âœ… Run a shell command
5. âœ… Read the full docs
6. âœ… Customize to your needs
7. âœ… Add custom tools
8. âœ… Share your improvements!

---

**Keep this handy while learning the agent! ğŸ“Œ**

Version 1.0 | For M3 Max optimization